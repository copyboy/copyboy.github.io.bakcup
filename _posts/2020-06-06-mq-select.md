---
layout: post
title: 软件 - 消息队列MQ
categories: [Blog]
description: 消息队列基础使用
keywords: MQ, RocketMQ, Kafka
---



# MQ 消息队列 - 待完善



## 业务场景



```
1. 使用亚马逊商户授权账号请求亚马逊接口数据
2. 接口返回数据不做处理直接丢入MQ，等待消费者进行消费
3. 消费者监听MQ消息，取得消息后入库，并验证是否有nextToken字段，如果有，组装调用生产者
```



限制：

- amazon调用接口有频率限制，所以想要在某个阶段进行延时请求
  - 组装阶段，在丢给MQ之前，进行频率的限制，解决思路是封装一个延时队列线程池，用来封装请求接口，在延时时间到后再丢给MQ，释放给请求器做处理
  - MQ阶段，MQ进行特定消息的延时释放，这个需要mq支持延时队列，如果不支持的话，有一个解决思路：使用mq自身的超时时间，当mq消息超时后进入死信队列，对死信队列进行监听处理。



<img src="..\images\typora\Snipaste_2020-06-06_15-31-08.png" alt="Snipaste_2020-06-06_15-31-08.png" style="zoom:60%;" />





## MQ 选型 ：

[5款主流分布式MQ消息队列](https://juejin.im/entry/5d0c7a90e51d45777540fdcb)

[关于MQ的几件小事](https://juejin.im/post/5ce55db3f265da1bb27706fe)



**综合对比下来，个人更倾向于使用RocketMQ，主要是使用场景都满足，不需要考虑很极端的应用场景**

**但是现在阿里云版本的实在是太贵，只能试着用开源版本的，**

**然而开源版本的，RocketMQ以及Kafka都不支持延时队列，这个就很头疼了**

但还是先尝试基础使用一下，以便做一些综合考虑。



## MQ 基础使用

### Rocket MQ 安装测试

#### 1. 下载

[最新安装地址](http://rocketmq.apache.org/dowloading/releases/)

[4.7.0下载页面](https://www.apache.org/dyn/closer.cgi?path=rocketmq/4.7.0/rocketmq-all-4.7.0-bin-release.zip)

[4.7.0 bfsu.edu 镜像下载地址](https://mirrors.bfsu.edu.cn/apache/rocketmq/4.7.0/rocketmq-all-4.7.0-bin-release.zip)

#### 2. 解压

linux环境

```bash
unzip rocketmq-all-4.7.0-bin-release
```

window环境解压随意

#### 3. 环境变量

linux环境

```bash
> vim /etc/profile
# 添加rocket_home 环境变量
export ROCKETMQ_HOME=/opt/took_kit/rocketmq-all-4.7.0-bin-release

# 使配置文件生效
> source /etc/profile
```



window环境变量

![image-20200529161931359](..\images\typora\image-20200529161931359.png)



#### 4. 默认配置启动

> Start Name Server

```bash
[root@sit-onerway rocketmq-all-4.7.0-bin-release]# nohup sh bin/mqnamesrv &
[1] 4899
[root@sit-onerway rocketmq-all-4.7.0-bin-release]# nohup: 忽略输入并把输出追加到"nohup.out"

[root@sit-onerway rocketmq-all-4.7.0-bin-release]# tailf nohup.out
Java HotSpot(TM) 64-Bit Server VM warning: Using the DefNew young collector with the CMS collector is deprecated and will likely be removed in a future release
Java HotSpot(TM) 64-Bit Server VM warning: UseCMSCompactAtFullCollection is deprecated and will likely be removed in a future release.
Java HotSpot(TM) 64-Bit Server VM warning: MaxNewSize (2097152k) is equal to or greater than the entire heap (2097152k).  A new max generation size of 2097088k will be used.
The Name Server boot success. serializeType=JSON
```

> Start Broker

```bash
[root@sit-onerway rocketmq-all-4.7.0-bin-release]# pwd
/opt/tool_kit/rocketmq-all-4.7.0-bin-release
[root@sit-onerway rocketmq-all-4.7.0-bin-release]# nohup sh bin/mqbroker -n 192.168.200.231:9876 autoCreateTopicEnable=true &
[2] 5145
[root@sit-onerway rocketmq-all-4.7.0-bin-release]# nohup: 忽略输入并把输出追加到"nohup.out"

[root@sit-onerway rocketmq-all-4.7.0-bin-release]# tailf nohup.out
Java HotSpot(TM) 64-Bit Server VM warning: Using the DefNew young collector with the CMS collector is deprecated and will likely be removed in a future release
Java HotSpot(TM) 64-Bit Server VM warning: UseCMSCompactAtFullCollection is deprecated and will likely be removed in a future release.
Java HotSpot(TM) 64-Bit Server VM warning: MaxNewSize (2097152k) is equal to or greater than the entire heap (2097152k).  A new max generation size of 2097088k will be used.
The Name Server boot success. serializeType=JSON
The broker[sit-onerway, 192.168.200.231:10911] boot success. serializeType=JSON and name server is localhost:9876
```



```bash
# 这一步尤其重要，设置NAMESRV_ADDR环境变量,否则 No route info of this topic, TopicTest
> export NAMESRV_ADDR=localhost:9876

```

之前NAMESRV_ADDR变量没有设置，导致各种问题，查找到一个说明比较详细的，可以看到相关日志

```bash
cd ~/logs/rocketmqlogs
# 查看相关日志
```

![image-20200529194046929](..\images\typora\image-20200529194046929.png)

[No route info of this topic](https://cloud.tencent.com/developer/article/1447341)



#### 5. 命令行工具测试连接

```bash
 > sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer
 SendResult [sendStatus=SEND_OK, msgId= ...

 > sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer
 ConsumeMessageThread_%d Receive New Messages: [MessageExt...
```

#### 6. 代码测试连接

使用官方的测试案例来做测试，下面Kafka使用 spring stream message  操作

```xml
<!-- 加入maven 依赖-->
<dependency>
    <groupId>org.rocketmq</groupId>
    <artifactId>spring-boot-starter-rocketmq</artifactId>
    <version>1.2.0.RELEASE</version>
</dependency>
```

```java
// 消费者
public class Consumer {

    public static void main(String[] args) throws InterruptedException, MQClientException {
        // Instantiate with specified consumer group name.
        DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("please_rename_unique_group_name");
        // Specify name server addresses.
        consumer.setNamesrvAddr("192.168.200.231:9876");
        // Subscribe one more more topics to consume.
        consumer.subscribe("TopicTest", "*");
        // Register callback to execute on arrival of messages fetched from brokers.
        consumer.registerMessageListener(new MessageListenerConcurrently() {
            @Override
            public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,
                                                            ConsumeConcurrentlyContext context) {
                System.out.printf("%s Receive New Messages: %s %n", Thread.currentThread().getName(), msgs);
                return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
            }
        });
        //Launch the consumer instance.
        consumer.start();
        System.out.printf("Consumer Started.%n");
    }
}
```

```java
// 生产者
public class OnewayProducer {
    public static void main(String[] args) throws Exception{
        //Instantiate with a producer group name.
        DefaultMQProducer producer = new DefaultMQProducer("please_rename_unique_group_name");
        // Specify name server addresses.
        producer.setNamesrvAddr("192.168.200.231:9876");
        //Launch the instance.
        producer.start();
        for (int i = 0; i < 100; i++) {
            //Create a message instance, specifying topic, tag and message body.
            Message msg = new Message("TopicTest" /* Topic */,
                                      "TagA" /* Tag */,
                    ("Hello RocketMQ " + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */
            );
            //Call send message to deliver message to one of brokers.
            producer.sendOneway(msg);
        }
        //Shut down once the producer instance is not longer in use.
        producer.shutdown();
    }
}
```

```log
# 消费者日志
ConsumeMessageThread_15 Receive New Messages: [MessageExt [queueId=1, storeSize=179, queueOffset=369, sysFlag=0, bornTimestamp=1590752868557, bornHost=/192.168.202.50:3491, storeTimestamp=1590752866770, storeHost=/192.168.200.231:10911, msgId=C0A8C8E700002A9F0000000000041338, commitLogOffset=267064, bodyCRC=884882597, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties={MIN_OFFSET=0, MAX_OFFSET=375, CONSUME_START_TIME=1590752869090, UNIQ_KEY=C0A8CA322E3C18B4AAC2947188CD004C, WAIT=true, TAGS=TagA}, body=17]]] 
```

#### 7. 可视化工具管理

名称：rocketmq-console

下载地址：https://github.com/apache/rocketmq-externals

克隆完整项目之后使用该项目下的子项目 rocketmq-console,修改参数后直接运行启动

```properties
spring.application.name=rocketmq-console
spring.http.encoding.charset=UTF-8
spring.http.encoding.enabled=true
spring.http.encoding.force=true
logging.config=classpath:logback.xml
# 修改此处为你的namesrv启动地址
rocketmq.config.namesrvAddr=192.168.200.231:9876
#if you use rocketmq version < 3.5.8, rocketmq.config.isVIPChannel should be false.default true
rocketmq.config.isVIPChannel=
# 本地路径的一个文件，看不太懂
rocketmq.config.dataPath=f:/tmp/rocketmq-console/data
```



![rocketmq-console](..\images\typora\image-20200529200657665.png)



### Rocket MQ 配置参数

 略

### Kafka安装测试

#### 1. 下载

[官网地址](http://kafka.apache.org/quickstart)

[2.5.0 下载页面](https://www.apache.org/dyn/closer.cgi?path=/kafka/2.5.0/kafka_2.12-2.5.0.tgz)

[2.5.0 镜像下载地址](https://mirrors.bfsu.edu.cn/apache/kafka/2.5.0/kafka_2.12-2.5.0.tgz)



#### 2. 解压

```bash
> tar -xzf kafka_2.12-2.5.0.tgz
> cd kafka_2.12-2.5.0
```

#### 3. 环境变量

#### 4. 默认配置启动

```bash
# zookeeper 启动，也就是注册中心
> bin/zookeeper-server-start.sh config/zookeeper.properties

# kafka 默认配置启动，也就是broker
> bin/kafka-server-start.sh config/server.properties

# 如果是服务器启动的话，需要更改server.properties配置后重启broker

```

![image-20200602153210728](..\images\typora\image-20200602153210728.png)

#### 5. 命令行测试

```bash
# 创建一个话题Topic
> bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test

# 查看创建的话题
> bin/kafka-topics.sh --list --bootstrap-server localhost:9092

# 发送消息,下面是一个console输入框，会将你输入的消息，当做生产者产生的消息存储起来， ctrl+c退出输入
> bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic test

# 启动一个消费者,消费broker中的消息
> bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
```



#### 6. 代码测试连接

如果kafka部署在服务器上，不是在本地，可能会报unknown host的问题，此时需要去修改server.properties，指定listeners启动的ip地址，这里使用**spring stream message** 消息模型来做测试。

```xml
<!--pom 配置 -->
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-stream-binder-kafka</artifactId>
    <version>3.0.5.RELEASE</version>
</dependency>

<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-web</artifactId>
</dependency>
```

```yml
# application.yml 配置，我在这里是用一个项目做的演示，下面的output,input 如果拆分的多个服务的话，会拆分在多个项目中
server:
  port: 8081
spring:
  application:
    name: producer
  cloud:
    stream:
      kafka:
        binder:
          brokers: 192.168.200.231:9092         #Kafka的消息中间件服务器
          zk-nodes: 192.168.200.231:2181        #Zookeeper的节点，如果集群，后面加,号分隔
          auto-create-topics: true        #如果设置为false,就不会自动创建Topic 有可能你Topic还没创建就直接调用了。
      bindings:
        output:      #这里用stream给我们提供的默认output，后面会讲到自定义output
          destination: stream-demo    #消息发往的目的地
          content-type: text/plain    #消息发送的格式，接收端不用指定格式，但是发送端要
        input:
          destination: stream-demo
```



```java
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

/**
 * @author qingdong.zhang@ronhan.com
 * @date 2020/6/2 15:01
 * @desc 控制器消息入口
 * @version 1.0
 */
@RestController
public class ProducerController {

    @Autowired
    private SendService sendService;

    @RequestMapping("/send/{msg}")
    public void send(@PathVariable("msg") String msg){
        sendService.sendMsg(msg);
    }
}
```

```java
import org.springframework.cloud.stream.annotation.EnableBinding;
import org.springframework.cloud.stream.annotation.StreamListener;
import org.springframework.cloud.stream.messaging.Sink;

/**
 * @author qingdong.zhang@ronhan.com
 * @date 2020/6/2 15:12
 * @desc 消息监听
 * @version 1.0
 */

@EnableBinding(Sink.class)
public class ReceiverService {

    @StreamListener(Sink.INPUT)
    public void receiver(Object payload){
        System.out.println("received >> "+ payload);
    }

}
```

```java
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.cloud.stream.annotation.EnableBinding;
import org.springframework.cloud.stream.messaging.Source;
import org.springframework.messaging.support.MessageBuilder;

/**
 * @author qingdong.zhang@ronhan.com
 * @date 2020/6/2 15:00
 * @desc 消息发送
 * @version 1.0
 */
@EnableBinding(Source.class)
public class SendService {

    @Autowired
    private Source source;

    public void sendMsg(String msg){
        System.out.println("send >>> " + msg);
        source.output().send(MessageBuilder.withPayload(msg).build());
    }
}
```

#### 7. 可视化工具管理

暂略。



## MQ 主从集群

![image-20200601153837999](..\images\typora\image-20200601153837999.png)

暂略。


